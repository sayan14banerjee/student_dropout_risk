{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "959dc1a0",
   "metadata": {},
   "source": [
    "### Setup & Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d07d1b0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data handling\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import yaml\n",
    "import joblib\n",
    "import time\n",
    "\n",
    "# Models\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import roc_auc_score, f1_score\n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "\n",
    "# MLflow\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "\n",
    "# Warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9a0d31c",
   "metadata": {},
   "source": [
    "### Load Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "008fb805",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'models': [{'name': 'lightgbm', 'type': 'lightgbm', 'max_depth': 7, 'learning_rate': 0.05, 'n_estimators': 500}, {'name': 'xgboost', 'type': 'xgboost', 'max_depth': 7, 'learning_rate': 0.05, 'n_estimators': 500}], 'metrics': {'primary': 'roc_auc', 'secondary': 'f1_score'}, 'thresholds': {'risk_flag': 0.7}, 'hyperparameter_search': {'method': 'gridsearch', 'lightgbm': {'num_leaves': [31, 50, 70], 'learning_rate': [0.01, 0.05, 0.1], 'n_estimators': [100, 300, 500]}, 'xgboost': {'max_depth': [3, 5, 7], 'learning_rate': [0.01, 0.05, 0.1], 'n_estimators': [100, 300, 500]}}, 'logging': {'experiment': 'dropout_prediction', 'tool': 'mlflow'}}\n"
     ]
    }
   ],
   "source": [
    "# Load YAML config\n",
    "with open(\"../../configs/training.yml\", \"r\") as f:\n",
    "    config = yaml.safe_load(f)\n",
    "\n",
    "print(config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5db5efea",
   "metadata": {},
   "source": [
    "### Load Preprocessed Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e0d98db0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape: (3539, 36) (3539,)\n",
      "Validation shape: (442, 36) (442,)\n"
     ]
    }
   ],
   "source": [
    "X_train = pd.read_csv(\"../../data/processed/X_train.csv\")\n",
    "y_train = pd.read_csv(\"../../data/processed/y_train.csv\").values.ravel()\n",
    "X_val = pd.read_csv(\"../../data/processed/X_val.csv\")\n",
    "y_val = pd.read_csv(\"../../data/processed/y_val.csv\").values.ravel()\n",
    "\n",
    "print(\"Train shape:\", X_train.shape, y_train.shape)\n",
    "print(\"Validation shape:\", X_val.shape, y_val.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1277e59",
   "metadata": {},
   "source": [
    "### Define Models & Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "12a6fd17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LightGBM\n",
    "lgb_config = next(m for m in config['models'] if m['type'] == 'lightgbm')\n",
    "lgb_model = lgb.LGBMClassifier(\n",
    "    max_depth=lgb_config['max_depth'],\n",
    "    learning_rate=lgb_config['learning_rate'],\n",
    "    n_estimators=lgb_config['n_estimators']\n",
    ")\n",
    "lgb_params = config['hyperparameter_search']['lightgbm']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2d779fe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# XGBoost\n",
    "xgb_config = next(m for m in config['models'] if m['type'] == 'xgboost')\n",
    "xgb_model = xgb.XGBClassifier(\n",
    "    max_depth=xgb_config['max_depth'],\n",
    "    learning_rate=xgb_config['learning_rate'],\n",
    "    n_estimators=xgb_config['n_estimators'],\n",
    "    use_label_encoder=False,\n",
    "    eval_metric='logloss'\n",
    ")\n",
    "xgb_params = config['hyperparameter_search']['xgboost']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc301545",
   "metadata": {},
   "source": [
    "### Initialize MLflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "94380bd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/10/06 11:48:42 INFO mlflow.tracking.fluent: Experiment with name 'dropout_prediction' does not exist. Creating a new experiment.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Experiment: artifact_location='file:///d:/Student_ropout_risk/src/models/mlruns/818261885524770619', creation_time=1759731522755, experiment_id='818261885524770619', last_update_time=1759731522755, lifecycle_stage='active', name='dropout_prediction', tags={}>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlflow.set_experiment(config['logging']['experiment'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd0751ba",
   "metadata": {},
   "source": [
    "### Train and Log LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1536daab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012169 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1049\n",
      "[LightGBM] [Info] Number of data points in the train set: 3539, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score -1.135451\n",
      "[LightGBM] [Info] Start training from score -1.717974\n",
      "[LightGBM] [Info] Start training from score -0.694561\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/10/06 11:50:15 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "2025/10/06 11:50:24 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LightGBM - ROC AUC: 0.8839, F1: 0.6304\n"
     ]
    }
   ],
   "source": [
    "with mlflow.start_run(run_name=\"LightGBM\"):\n",
    "    start = time.time()\n",
    "    \n",
    "    # GridSearchCV for hyperparameter tuning\n",
    "    lgb_grid = GridSearchCV(lgb_model, lgb_params, cv=3, scoring='roc_auc', n_jobs=-1) # type: ignore\n",
    "    lgb_grid.fit(X_train, y_train)\n",
    "    \n",
    "    # Predict on validation\n",
    "    y_val_pred = lgb_grid.predict(X_val)\n",
    "    y_val_proba = lgb_grid.predict_proba(X_val)[:,1]\n",
    "    \n",
    "    # Metrics\n",
    "    roc_auc = roc_auc_score(y_val, lgb_grid.predict_proba(X_val), multi_class='ovr')\n",
    "    f1 = f1_score(y_val, y_val_pred, average='macro')\n",
    "    end = time.time()\n",
    "    \n",
    "    # Log\n",
    "    mlflow.log_params(lgb_grid.best_params_)\n",
    "    mlflow.log_metric(\"roc_auc\", roc_auc) # type: ignore\n",
    "    mlflow.log_metric(\"f1_score\", f1) # type: ignore\n",
    "    mlflow.log_metric(\"train_time_sec\", end-start)\n",
    "    mlflow.sklearn.log_model(lgb_grid.best_estimator_, \"model\") # type: ignore\n",
    "    \n",
    "    print(f\"LightGBM - ROC AUC: {roc_auc:.4f}, F1: {f1:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73aa4813",
   "metadata": {},
   "source": [
    "### Train and Log XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e1a784e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/10/06 11:50:59 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "2025/10/06 11:51:03 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost - ROC AUC: 0.8636, F1: 0.6695\n"
     ]
    }
   ],
   "source": [
    "with mlflow.start_run(run_name=\"XGBoost\"):\n",
    "    start = time.time()\n",
    "    \n",
    "    # GridSearchCV for hyperparameter tuning\n",
    "    xgb_grid = GridSearchCV(xgb_model, xgb_params, cv=3, scoring='roc_auc', n_jobs=-1)\n",
    "    xgb_grid.fit(X_train, y_train)\n",
    "    \n",
    "    # Predict on validation\n",
    "    y_val_pred = xgb_grid.predict(X_val)\n",
    "    y_val_proba = xgb_grid.predict_proba(X_val)[:,1]\n",
    "    \n",
    "    # Metrics\n",
    "    roc_auc = roc_auc_score(y_val, xgb_grid.predict_proba(X_val), multi_class='ovr')\n",
    "    f1 = f1_score(y_val, y_val_pred, average='macro')\n",
    "    end = time.time()\n",
    "    \n",
    "    # Log\n",
    "    mlflow.log_params(xgb_grid.best_params_)\n",
    "    mlflow.log_metric(\"roc_auc\", roc_auc) # type: ignore\n",
    "    mlflow.log_metric(\"f1_score\", f1) # type: ignore\n",
    "    mlflow.log_metric(\"train_time_sec\", end-start)\n",
    "    mlflow.sklearn.log_model(xgb_grid.best_estimator_, \"model\") # type: ignore\n",
    "    \n",
    "    print(f\"XGBoost - ROC AUC: {roc_auc:.4f}, F1: {f1:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddcecb40",
   "metadata": {},
   "source": [
    "### Compare Models & Select Best|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "188bef70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Model: LightGBM with ROC-AUC = 0.8839\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['../../models/best_model.pkl']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example: Compare ROC-AUC on validation\n",
    "results = {\n",
    "    \"LightGBM\": roc_auc_score(y_val, lgb_grid.predict_proba(X_val), multi_class='ovr'),\n",
    "    \"XGBoost\": roc_auc_score(y_val, xgb_grid.predict_proba(X_val), multi_class='ovr')\n",
    "}\n",
    "\n",
    "best_model_name = max(results, key=results.get) # type: ignore\n",
    "best_model = lgb_grid.best_estimator_ if best_model_name==\"LightGBM\" else xgb_grid.best_estimator_\n",
    "\n",
    "print(f\"Best Model: {best_model_name} with ROC-AUC = {results[best_model_name]:.4f}\")\n",
    "\n",
    "# Save best model\n",
    "joblib.dump(best_model, \"../../models/best_model.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "972caf1e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
